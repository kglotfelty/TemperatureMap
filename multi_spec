#!/usr/bin/env python

# Copyright (C) 2017,2020 Smithsonian Astrophysical Observatory
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
#

"Fit spectral map"

import sys
import os
import numpy as np

import pycrates as pyc

# I need to import * here because I don't know what's in the
# user's init command (group_counts/etc)
# pylint: disable=undefined-variable
from sherpa.astro.ui import *   # pylint: disable=wildcard-import

# I need to import this after sherpa.
import logging                  # pylint: disable=wrong-import-order

import ciao_contrib.logger_wrapper as lw
from ciao_contrib.runtool import make_tool

logging.getLogger("sherpa").setLevel(logging.ERROR)

TOOLNAME = "multi_spec"
__REVISION__ = "06 January 2021"
lw.initialize_logger(TOOLNAME)
VERB0 = lw.get_logger(TOOLNAME).verbose0
VERB1 = lw.get_logger(TOOLNAME).verbose1
VERB2 = lw.get_logger(TOOLNAME).verbose2
VERB3 = lw.get_logger(TOOLNAME).verbose3
VERB5 = lw.get_logger(TOOLNAME).verbose5


def load_bkg_array(channel, data):
    """
    Since there is no dedicated load_bkg_array routine we have
    to load background as a source, then
    get and set to be assocated with source 1.
    """
    load_arrays("delete_me", channel, data, DataPHA)

    set_bkg(1, get_data("delete_me"))
    delete_data("delete_me")


def _get_arf(grid, arffile):
    """
    Handle single vs. multi arfs
    """
    if os.path.exists(arffile):
        load_arf(arffile)
    else:
        load_arf(f"{arffile}_{grid+1}.arf")


def _get_rmf(grid, rmffile):
    """
    Handle single vs. multi rmfs
    """
    if os.path.exists(rmffile):
        load_rmf(rmffile)
    else:
        load_rmf(f"{rmffile}_{grid+1}.rmf")


class MultiSpectrum():
    'Class to hold info for multiple spectra stored as image'

    def __init__(self, infile, bkgfile):
        'Define all the properties and load the spectral maps'
        self.ms_vals = None
        self.exposure = None
        self.bg_vals = None
        self.bg_exposure = None
        self.arffile = None
        self.rmffile = None
        self.model = None
        self.init_str = None
        self.conclusion = None
        self.retstr = None
        self.out_cols = None
        self.mask_id = None
        self.ret_val = None
        self._load_spectra(infile, bkgfile)

    def _load_spectra(self, infile, bkgfile):
        'Load spectra'

        #
        # The spectrum is stored at a 2D image where:
        #
        #   x: [1] is mask number
        #   y: [0] is channel
        #   z: [pixel value] is counts
        ms_img = pyc.read_file(infile)
        self.ms_vals = ms_img.get_image().values
        self.exposure = ms_img.get_key_value("EXPOSURE")

        if bkgfile:
            bg_img = pyc.read_file(bkgfile)
            self.bg_vals = bg_img.get_image().values
            self.bg_exposure = bg_img.get_key_value("EXPOSURE")
            if self.ms_vals.shape != self.bg_vals.shape:
                msg = "Source and background spectrum must be same size"
                raise RuntimeError(msg)
        else:
            self.bg_vals = None
            self.bg_exposure = None

    def set_responses(self, arffile, rmffile):
        'Set response file names'
        self.arffile = arffile
        self.rmffile = rmffile

    def set_model(self, model, init, retval, conclusion):
        'Setup model'
        self.model = model
        self.init_str = init
        self.retstr = retval
        self.conclusion = conclusion

        cols = self.retstr+""
        for digit in "().":
            cols = cols.replace(digit, "_")
        while '__' in cols:
            cols = cols.replace("__", "_")

        self.out_cols = cols.split(",")

    def my_fit(self, grid):
        '''Setup for the fit'''

        # pylint: disable=eval-used
        # pylint: disable=exec-used

        VERB2("Fitting mask_id={}".format(grid+1))
        set_xschatter(0)

        try:
            channel = np.arange(self.ms_vals.shape[0])+1  # Channels go 1 to N
            set_source(self.model)

            # load column from image into a PHA dataset
            # backscale (assumes to be 1)
            load_arrays(1, channel, self.ms_vals[:, grid], DataPHA)
            set_exposure(1, self.exposure)

            if self.bg_vals is not None:
                load_bkg_array(channel, self.bg_vals[:, grid])
                set_exposure(1, self.bg_exposure, 1)
                subtract()

            _get_arf(grid, self.arffile)
            _get_rmf(grid, self.rmffile)
            exec(self.init_str)
            fit()
            exec(self.conclusion)

            retval = eval(self.retstr)
            try:
                # See if we get a single value or a list
                iter(retval)
            except TypeError:
                # single value so make it a list
                retval = (retval,)

            return retval
        except Exception as badfit:
            print(badfit)
            return (np.nan,)

    def fit(self):
        'Do the fit'
        #
        # Setup arrays
        #
        nspec = self.ms_vals.shape[1]
        maskids = np.arange(nspec)

        # randomize things so parallel map has better shot at
        # keeping queue full
        np.random.shuffle(maskids)

        #
        # Iterate over grid of points
        #
        from sherpa.utils import parallel_map
        savedata = parallel_map(self.my_fit, maskids.tolist())

        #
        # Savedata are now in random order, want to sort
        #
        outdata = list(zip((maskids+1).tolist(), savedata))
        outdata.sort()
        self.mask_id = [x[0] for x in outdata]
        self.ret_val = [x[1] for x in outdata]

    def save(self, outroot, infile, clobber, pars):
        'Save outputs'
        from ciao_contrib.runtool import add_tool_history

        outfile = outroot+".fits"

        cols = self.out_cols

        # Unpack the data returned from the parallel_map
        savecols = {}
        for _col in cols:
            savecols[_col] = []

        for vals in self.ret_val:
            for indx, _val in enumerate(vals):
                savecols[cols[indx]].append(_val)

        savecols["mask_id"] = self.mask_id
        cols.insert(0, "mask_id")

        from crates_contrib.utils import write_columns
        write_columns(outfile, savecols, colnames=cols,
                      clobber=clobber, format="fits")
        add_tool_history(outfile, TOOLNAME, pars, toolversion=__REVISION__)

        # Save images of each returned parameter value

        dmf = make_tool("dmmaskfill")
        for _col in cols[1:]:
            dmf(outfile+f"[cols mask_id,{_col}]",
                infile+"[opt type=i4]", outroot+f".{_col}.map",
                clobber=True)
            add_tool_history(outroot+f".{_col}.map", TOOLNAME,
                             pars, toolversion=__REVISION__)


def make_spectral_map(infile, eventfile, outroot, bkg=""):
    'Extract spectra into a 2D image'

    from pycrates import read_file

    VERB1("Creating spectrum image")

    mask = read_file(infile).get_image()
    colname = mask.name.replace(".", "_")
    maxval = np.max(mask.values)

    try:
        dmi = make_tool("dmimgpick")
        dmi(infile=eventfile, imgfile=infile, outfile=outroot+".mapped",
            method="closest", clobber=True, verbose=0)

        dmc = make_tool("dmcopy")
        outf = "[bin {col}=1:{maxval}:1,pi=1:1024:1]"
        outf = outf.format(col=colname, maxval=maxval)
        dmc(dmi.outfile+outf,
            outfile=outroot+"{bkg}.spectra".format(bkg=bkg),
            clobber=True)
    finally:
        if os.path.exists(dmi.outfile):
            os.remove(dmi.outfile)

    return dmc.outfile


def root_clobber(outroot, outcols, clobber):
    'Clobber output files'
    from ciao_contrib._tools.fileio import outfile_clobber_checks

    outfile_clobber_checks(clobber, outroot+".spectra")
    outfile_clobber_checks(clobber, outroot+"bkg.spectra")
    outfile_clobber_checks(clobber, outroot+".dat")

    cols = outcols+""
    for digit in "().":
        cols = cols.replace(digit, "_")
    while '__' in cols:
        cols = cols.replace("__", "_")

    for _col in cols:
        outfile_clobber_checks(clobber, outroot+f".{_col}.map")


@lw.handle_ciao_errors(TOOLNAME, __REVISION__)
def main():
    'The Main'
    from ciao_contrib.param_soaker import get_params
    # Load parameters
    pars = get_params(TOOLNAME, "rw", sys.argv,
                      verbose={"set": lw.set_verbosity, "cmd": VERB1})

    root_clobber(pars["outroot"], pars["return_value"], pars["clobber"])

    spectra = make_spectral_map(pars["infile"],
                                pars["evtfile"], pars["outroot"])
    if (len(pars["bkgevt"]) > 0) and "none" != pars["bkgevt"].lower():
        bkg_spectra = make_spectral_map(pars["infile"], pars["bkgevt"],
                                        pars["outroot"], bkg="_bkg")
    else:
        bkg_spectra = ""

    multi = MultiSpectrum(spectra, bkg_spectra)
    multi.set_responses(pars["arffile"], pars["rmffile"])
    multi.set_model(pars["srcmodel"], pars["initialization"],
                    pars["return_value"], pars["conclusion"])
    multi.fit()
    multi.save(pars["outroot"], pars["infile"], pars["clobber"], pars)


if __name__ == "__main__":
    main()
